---
title: "Lab 08 - University of Edinburgh Art Collection"
author: "Fanyi Zeng"
date: "03/11/22"
output: github_document
---

### Load packages and data

```{r load-packages, message = FALSE}
library(robotstxt)
library(rvest)
library(tidyverse)
library(dplyr)
library(skimr)
```

```{r load-data, message = FALSE, eval = FALSE}
paths_allowed("https://collections.ed.ac.uk/art)")
```

### Read the page

```{r url}
# set url
first_url <- "https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0"
# read html page
page <- read_html(first_url)
```

### Save the titles

```{r titles}
titles <- page %>%
  html_nodes(".iteminfo") %>%
  html_node("h3 a") %>%
  html_text() %>%
  str_squish()
titles
```

### Save the links

```{r links}
links <- page %>%
  html_nodes(".iteminfo") %>%   # same nodes
  html_node("h3 a") %>%         # as before
  html_attr("href") %>%         # but get href attribute instead of text
  str_replace(".", "https://collections.ed.ac.uk/art")
links
```

### Save the artists

```{r artists}
artists <- page %>%
  html_nodes(".iteminfo") %>%
  html_node(".artist") %>%
  html_text()
artists
```

### Create a dataframe

```{r df1}
first_ten <- tibble(
  title = titles,
  artist = artists,
  link = links
) 
first_ten  
```

### Scrape the next page

```{r url2}
# set url
second_url <- "https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=10"
# read html page
page2 <- read_html(second_url)
```

### Save the titles

```{r titles2}
titles2 <- page2 %>%
  html_nodes(".iteminfo") %>%
  html_node("h3 a") %>%
  html_text() %>%
  str_squish()
titles2
```

### Save the links

```{r links2}
links2 <- page2 %>%
  html_nodes(".iteminfo") %>%   # same nodes
  html_node("h3 a") %>%         # as before
  html_attr("href") %>%         # but get href attribute instead of text
  str_replace(".", "https://collections.ed.ac.uk/art")
links2
```

### Save the artists

```{r artists2}
artists2 <- page2 %>%
  html_nodes(".iteminfo") %>%
  html_node(".artist") %>%
  html_text()
artists2
```

### Create a dataframe

```{r df1}
second_ten <- tibble(
  title = titles2,
  artist = artists2,
  link = links2
) 
second_ten  
```

### Create a function

```{r function}
scrape_page <- function(url){
   page <- read_html(url)
titles <- page %>%
  html_nodes(".iteminfo") %>%
  html_node("h3 a") %>%
  html_text() %>%
  str_squish()
links <- page %>%
  html_nodes(".iteminfo") %>%   
  html_node("h3 a") %>%         
  html_attr("href") %>%         
  str_replace(".", "https://collections.ed.ac.uk/art")
artists <- page %>%
  html_nodes(".iteminfo") %>%
  html_node(".artist") %>%
  html_text()
ten <- tibble(
  title = titles,
  artist = artists,
  link = links)
}
```

### Test the function

It works!!

```{r test}
first_page <- scrape_page(first_url)
second_page <- scrape_page(second_url)
```

### Iteration, mapping, & saving as csv

```{r iterate}
urls <- paste0("https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=",seq(0,2980,by=10))
urls
```

I am converting the following code into comments because it is going to take a long time knitting. I already have the dataframe saved in my folder.

```{r mapping}
#uoe_art <- map_dfr(urls, scrape_page)
#uoe_art
```

```{r save}
#write.csv(uoe_art, "uoe_art.csv",row.names = F)
```

### Read my saved data

```{r read}
uoe_art <- read_csv("uoe_art.csv")
```

### Separating title and date

```{r separate-title-date, error = TRUE}
uoe_art <- uoe_art %>%
  separate(title, into = c("title", "date"), sep = "\\(") %>%
  mutate(year = str_remove(date, "\\)") %>% as.numeric()) %>%
  select(title, artist, year, link)
```

The warnings tell us three things: 1. there are redundant art pieces (with the same title and year); 2. there are art pieces with missing titles or artists (which are then filled with "NA"); 3. there are art pieces with missing years (which are then filled with "NA").

### Analysis

115 pieces are missing artist info, and 1411 pieces missing year info.

```{r sum}
skim(uoe_art)
```

There is an art piece out of the ordinary - it has a year of "2". This happened because the art piece has two numbers, "2" and "1964". We will need to correct its year to "1964".

```{r bar}
uoe_art %>%
  ggplot(aes(x=year)) +
  geom_histogram()
```

There are two ways to correct the year: if_else and case_when.

Using if_else:

```{r ifelse}
uoe_art_2 <- uoe_art %>%
  mutate(year=if_else(year==2, 1964, year, NA_real_))
```

Using case_when:

```{r casewhen}
uoe_art_new <- uoe_art %>%
  mutate(year = case_when(
    year == 2 ~ 1964,
    year != 2 ~ year))
```

I limit the years to between 1820 (min) and 2020 (max) and make a new histogram. Either uoe_art_new or uoe_art_2 will work. They are the same.

```{r newbar}
uoe_art_new %>%
  ggplot(aes(x=year)) +
  geom_histogram(binwidth=10) +
  xlim(1819,2020) +
  labs(title = "University of Edinburgh Artwork Collection (1819~2020)", subtitle = "As of 03/13/2022", x = "Year of Artwork Pieces", y = "Number of Artwork Pieces")
```

The most featured known artist is Emma Gillies. From this website (https://www.ed.ac.uk/news/2014/emma-gillies-031214), I learned that her family was renown in the art field in 20th century and very closely related to the U of Edinburgh. Emma was a ceramic student there, and her brother William was a teacher for 40 years as well as the Principal for 6 tears.

```{r count}
uoe_art_new %>%
  count(artist) %>%
  arrange(desc(n))
```

11 pieces have the word "child" in them.

```{r child}
uoe_art_new %>%
  filter(
  str_detect(title, "child")|
  str_detect(title, "Child")
  )
```
